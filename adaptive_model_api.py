import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
import warnings
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
import joblib

warnings.filterwarnings('ignore')

class AdaptiveSuTuketimModeli:
    def __init__(self, model_path="adaptive_model.joblib"):
        self.model_path = model_path
        self.learning_data = []
        
        # DAHA AKILLI BAÅLANGIÃ‡ THRESHOLD'LARI
        self.adaptive_thresholds = {
            'varyasyon_esik': 1.2,    # Daha hassas baÅŸla
            'yuksek_tuketim_esik': 40, # Daha dÃ¼ÅŸÃ¼k baÅŸla
            'trend_esik': 0.25,       # Daha hassas trend
            'sifir_esik': 1           # Daha hassas sÄ±fÄ±r tespiti
        }
        
        self.pattern_memory = {}
        self.performance_history = []
        
        # OTOMATÄ°K Ã–ÄRENME VERÄ°SÄ°
        self._initialize_with_synthetic_data()
        self.load_model()
    
    def _initialize_with_synthetic_data(self):
        """Sentetik veri ile hemen Ã¶ÄŸrenmeye baÅŸla"""
        print("ğŸ¤– Sentetik veri ile AI eÄŸitiliyor...")
        
        # BaÅŸarÄ±lÄ± tahminler (gerÃ§ek hayattan beklenen pattern'ler)
        successful_patterns = [
            # Normal pattern'ler - DÃ¼ÅŸÃ¼k risk
            {'sifir_sayisi': 0, 'varyasyon': 0.5, 'trend': 0.05, 'tuketim': 15, 'risk': 'DÃ¼ÅŸÃ¼k'},
            {'sifir_sayisi': 0, 'varyasyon': 0.8, 'trend': 0.08, 'tuketim': 25, 'risk': 'DÃ¼ÅŸÃ¼k'},
            
            # Orta risk pattern'leri
            {'sifir_sayisi': 1, 'varyasyon': 1.1, 'trend': 0.15, 'tuketim': 35, 'risk': 'Orta'},
            {'sifir_sayisi': 0, 'varyasyon': 1.4, 'trend': 0.12, 'tuketim': 45, 'risk': 'Orta'},
            
            # YÃ¼ksek risk pattern'leri
            {'sifir_sayisi': 2, 'varyasyon': 1.8, 'trend': 0.35, 'tuketim': 60, 'risk': 'YÃ¼ksek'},
            {'sifir_sayisi': 3, 'varyasyon': 2.2, 'trend': 0.45, 'tuketim': 80, 'risk': 'YÃ¼ksek'},
        ]
        
        # Sentetik feedback'ler oluÅŸtur
        for pattern in successful_patterns:
            feedback = {
                'tesisat_no': f"SYNTHETIC_{hash(str(pattern))}",
                'gercek_durum': pattern['risk'],
                'tahmin_durum': pattern['risk'],  # DoÄŸru tahmin
                'tarih': datetime.now(),
                'basari': 1,
                'pattern': pattern
            }
            self.performance_history.append(feedback)
        
        print(f"âœ… {len(successful_patterns)} sentetik pattern ile AI eÄŸitildi")
    
    def load_model(self):
        """Ã–ÄŸrenilmiÅŸ modeli yÃ¼kler - daha gÃ¼Ã§lÃ¼ hata yÃ¶netimi"""
        try:
            if os.path.exists(self.model_path):
                model_data = joblib.load(self.model_path)
                self.adaptive_thresholds = model_data.get('adaptive_thresholds', self.adaptive_thresholds)
                self.pattern_memory = model_data.get('pattern_memory', {})
                
                # Mevcut performans geÃ§miÅŸine ekle (Ã§akÄ±ÅŸma olmasÄ±n)
                existing_history = model_data.get('performance_history', [])
                existing_ids = [p.get('tesisat_no') for p in self.performance_history]
                
                for item in existing_history:
                    if item.get('tesisat_no') not in existing_ids:
                        self.performance_history.append(item)
                
                print(f"âœ… Ã–ÄŸrenilmiÅŸ model yÃ¼klendi. Toplam gÃ¶zlem: {len(self.performance_history)}")
                
                # Threshold'larÄ± optimize et
                self.adaptive_learning()
                
        except Exception as e:
            print(f"âŒ Model yÃ¼klenemedi, sentetik veri ile devam: {e}")
    
    def save_model(self):
        """Modeli kaydeder - daha gÃ¼venli"""
        try:
            model_data = {
                'adaptive_thresholds': self.adaptive_thresholds,
                'pattern_memory': self.pattern_memory,
                'performance_history': self.performance_history[-2000:],  # Bellek optimizasyonu
                'last_update': datetime.now(),
                'version': '1.1',
                'total_observations': len(self.performance_history)
            }
            joblib.dump(model_data, self.model_path)
            print(f"âœ… Model kaydedildi. Toplam gÃ¶zlem: {len(self.performance_history)}")
        except Exception as e:
            print(f"âŒ Model kaydedilemedi: {e}")
    
    def learn_from_feedback(self, tesisat_no, gercek_durum, tahmin_durum, pattern_data=None):
        """GeliÅŸmiÅŸ geri bildirimle Ã¶ÄŸrenme"""
        feedback = {
            'tesisat_no': tesisat_no,
            'gercek_durum': gercek_durum,
            'tahmin_durum': tahmin_durum,
            'tarih': datetime.now(),
            'basari': 1 if gercek_durum == tahmin_durum else 0,
            'pattern': pattern_data
        }
        
        # Benzersiz feedback'leri ekle
        existing_ids = [p.get('tesisat_no') for p in self.performance_history]
        if tesisat_no not in existing_ids:
            self.performance_history.append(feedback)
        
        # PerformansÄ± hemen gÃ¼ncelle
        self.adaptive_learning()
        self.save_model()
        
        print(f"ğŸ“ Yeni feedback: {tesisat_no} | GerÃ§ek: {gercek_durum} | Tahmin: {tahmin_durum} | BaÅŸarÄ±: {feedback['basari']}")
    
    def adaptive_learning(self):
        """Daha agresif adaptif Ã¶ÄŸrenme"""
        if len(self.performance_history) < 10:
            return
        
        # Son 500 kaydÄ± deÄŸerlendir
        evaluation_data = self.performance_history[-500:] if len(self.performance_history) > 500 else self.performance_history
        basari_orani = sum([p['basari'] for p in evaluation_data]) / len(evaluation_data)
        
        print(f"ğŸ¯ Ã–ÄŸrenme DeÄŸerlendirmesi: {len(evaluation_data)} gÃ¶zlem, BaÅŸarÄ±: {basari_orani:.1%}")
        
        # DAHA HIZLI Ã–ÄRENME
        learning_rate = 0.1  # Ã–ÄŸrenme hÄ±zÄ±nÄ± artÄ±r
        
        if basari_orani < 0.6:  # BaÅŸarÄ± dÃ¼ÅŸÃ¼kse threshold'larÄ± optimize et
            self.adaptive_thresholds['varyasyon_esik'] *= (1 - learning_rate)
            self.adaptive_thresholds['trend_esik'] *= (1 - learning_rate)
            self.adaptive_thresholds['yuksek_tuketim_esik'] *= (1 - learning_rate * 0.5)
            print("ğŸ”§ Threshold'lar sÄ±kÄ±laÅŸtÄ±rÄ±ldÄ± (dÃ¼ÅŸÃ¼k baÅŸarÄ±)")
            
        elif basari_orani > 0.85:  # BaÅŸarÄ± yÃ¼ksekse threshold'larÄ± gevÅŸet
            self.adaptive_thresholds['varyasyon_esik'] *= (1 + learning_rate)
            self.adaptive_thresholds['trend_esik'] *= (1 + learning_rate)
            self.adaptive_thresholds['yuksek_tuketim_esik'] *= (1 + learning_rate * 0.5)
            print("ğŸ”§ Threshold'lar gevÅŸetildi (yÃ¼ksek baÅŸarÄ±)")
        
        # Threshold'larÄ± makul sÄ±nÄ±rlarda tut
        self.adaptive_thresholds['varyasyon_esik'] = max(0.3, min(3.0, self.adaptive_thresholds['varyasyon_esik']))
        self.adaptive_thresholds['trend_esik'] = max(0.05, min(1.0, self.adaptive_thresholds['trend_esik']))
        self.adaptive_thresholds['yuksek_tuketim_esik'] = max(10, min(200, self.adaptive_thresholds['yuksek_tuketim_esik']))
        self.adaptive_thresholds['sifir_esik'] = max(1, min(5, self.adaptive_thresholds['sifir_esik']))
        
        print(f"ğŸ“Š Yeni Threshold'lar: {self.adaptive_thresholds}")
    
    def auto_learn_from_analysis(self, tesisat_verisi, analiz_sonucu):
        """Analiz sonuÃ§larÄ±ndan otomatik Ã¶ÄŸrenme"""
        if len(tesisat_verisi) < 6:  # Yeterli veri yoksa Ã¶ÄŸrenme
            return
        
        tuketimler = tesisat_verisi['AKTIF_m3'].values
        
        # Pattern verilerini topla
        pattern_data = {
            'sifir_sayisi': sum(tuketimler == 0),
            'varyasyon': np.std(tuketimler) / np.mean(tuketimler) if np.mean(tuketimler) > 0 else 0,
            'trend': self._calculate_trend(tuketimler),
            'tuketim': np.mean(tuketimler),
            'length': len(tuketimler)
        }
        
        # Pattern'i hafÄ±zaya kaydet
        pattern_key = f"pattern_{hash(str(pattern_data))}"
        self.pattern_memory[pattern_key] = {
            'pattern': pattern_data,
            'risk_seviyesi': analiz_sonucu['risk_seviyesi'],
            'count': self.pattern_memory.get(pattern_key, {}).get('count', 0) + 1,
            'last_seen': datetime.now()
        }
    
    def _calculate_trend(self, tuketimler):
        """Trend hesaplama"""
        if len(tuketimler) < 3:
            return 0
        return (tuketimler[-1] - tuketimler[0]) / tuketimler[0] if tuketimler[0] > 0 else 0

    def gelismis_davranis_analizi(self, tesisat_verisi):
        """GeliÅŸmiÅŸ davranÄ±ÅŸ analizi - Ã¶ÄŸrenme entegre"""
        if len(tesisat_verisi) < 3:
            return self._create_default_analysis("Yetersiz veri", "Orta", 0)
        
        tuketimler = tesisat_verisi['AKTIF_m3'].values
        tarihler = tesisat_verisi['OKUMA_TARIHI']
        
        # Ä°statistiksel Ã¶zellikler
        sifir_sayisi = sum(tuketimler == 0)
        sifir_orani = sifir_sayisi / len(tuketimler)
        std_dev = np.std(tuketimler) if len(tuketimler) > 1 else 0
        mean_tuketim = np.mean(tuketimler) if len(tuketimler) > 0 else 0
        varyasyon_katsayisi = std_dev / mean_tuketim if mean_tuketim > 0 else 0
        
        # Trend analizi
        trend_degeri = self._calculate_trend(tuketimler)
        
        # Ã–ÄRENÄ°LMÄ°Å THRESHOLD'LAR ile risk puanÄ± hesaplama
        risk_puan = self._calculate_adaptive_risk_score(
            sifir_sayisi, sifir_orani, varyasyon_katsayisi, 
            trend_degeri, mean_tuketim, len(tuketimler)
        )
        
        # Risk seviyesi belirleme
        risk_seviyesi = self._determine_risk_level(risk_puan)
        
        # ÅÃ¼pheli dÃ¶nem tespiti
        supheli_donemler = self._find_suspicious_periods(tuketimler, tarihler, sifir_sayisi)
        
        # Ã–ÄRENÄ°LMÄ°Å YORUM oluÅŸturma
        yorum = self._adaptive_yorum_olustur(
            risk_seviyesi, risk_puan, sifir_sayisi, 
            varyasyon_katsayisi, trend_degeri, mean_tuketim
        )
        
        # OTOMATÄ°K Ã–ÄRENME
        self.auto_learn_from_analysis(tesisat_verisi, {
            'risk_seviyesi': risk_seviyesi,
            'risk_puan': risk_puan,
            'yorum': yorum
        })
        
        return {
            'yorum': yorum,
            'supheli_donemler': supheli_donemler,
            'risk_seviyesi': risk_seviyesi,
            'risk_puan': risk_puan,
            'std_dev': std_dev,
            'mean_tuketim': mean_tuketim,
            'pattern_data': {
                'sifir_sayisi': sifir_sayisi,
                'varyasyon_katsayisi': varyasyon_katsayisi,
                'trend_degeri': trend_degeri,
                'mean_tuketim': mean_tuketim
            }
        }
    
    def _calculate_adaptive_risk_score(self, sifir_sayisi, sifir_orani, varyasyon_katsayisi, trend_degeri, mean_tuketim, data_length):
        """Adaptive risk skoru hesaplama"""
        risk_puan = 0
        
        # 1. SÄ±fÄ±r tÃ¼ketim analizi - adaptive threshold
        if sifir_sayisi >= self.adaptive_thresholds['sifir_esik']:
            risk_puan += 3
        elif sifir_sayisi == 1:
            risk_puan += 1
        
        if sifir_orani > 0.5:
            risk_puan += 2
        
        # 2. Varyasyon analizi - adaptive threshold
        varyasyon_esik = self.adaptive_thresholds['varyasyon_esik']
        if varyasyon_katsayisi > varyasyon_esik:
            risk_puan += 2
        elif varyasyon_katsayisi > varyasyon_esik * 0.7:
            risk_puan += 1
        
        # 3. Trend analizi - adaptive threshold  
        trend_esik = self.adaptive_thresholds['trend_esik']
        if abs(trend_degeri) > trend_esik:
            risk_puan += 2
        elif abs(trend_degeri) > trend_esik * 0.7:
            risk_puan += 1
        
        # 4. Son dÃ¶nem sÄ±fÄ±r tÃ¼ketim (basit kontrol)
        # Bu kÄ±sÄ±m tesisat_verisi gerektirdiÄŸi iÃ§in ana fonksiyonda yapÄ±lÄ±yor
        
        # 5. Anormal yÃ¼ksek tÃ¼ketim - adaptive threshold
        yuksek_tuketim_esik = self.adaptive_thresholds['yuksek_tuketim_esik']
        if mean_tuketim > yuksek_tuketim_esik:
            risk_puan += 2
        elif mean_tuketim > yuksek_tuketim_esik * 0.7:
            risk_puan += 1
        
        return risk_puan
    
    def _determine_risk_level(self, risk_puan):
        """Risk seviyesi belirleme"""
        if risk_puan >= 5:
            return "YÃ¼ksek"
        elif risk_puan >= 3:
            return "Orta"
        else:
            return "DÃ¼ÅŸÃ¼k"
    
    def _find_suspicious_periods(self, tuketimler, tarihler, sifir_sayisi):
        """ÅÃ¼pheli dÃ¶nemleri bul"""
        supheli_donemler = []
        if sifir_sayisi > 0:
            for idx in np.where(tuketimler == 0)[0]:
                if idx < len(tarihler):
                    try:
                        tarih_obj = pd.Timestamp(tarihler.iloc[idx])
                        supheli_donemler.append(tarih_obj.strftime('%m/%Y'))
                    except:
                        continue
        return ", ".join(supheli_donemler) if supheli_donemler else "Yok"
    
    def _adaptive_yorum_olustur(self, risk_seviyesi, risk_puan, sifir_sayisi, varyasyon_katsayisi, trend_degeri, mean_tuketim):
        """Adaptive yorum oluÅŸturma"""
        
        if risk_seviyesi == "YÃ¼ksek":
            yorumlar = []
            
            if sifir_sayisi >= self.adaptive_thresholds['sifir_esik']:
                yorumlar.append("DÃ¼zensiz sÄ±fÄ±r tÃ¼ketim paterni")
            if varyasyon_katsayisi > self.adaptive_thresholds['varyasyon_esik']:
                yorumlar.append("YÃ¼ksek tÃ¼ketim dalgalanmasÄ±")
            if abs(trend_degeri) > self.adaptive_thresholds['trend_esik']:
                yorumlar.append(f"{'YÃ¼kselen' if trend_degeri > 0 else 'DÃ¼ÅŸen'} tÃ¼ketim trendi")
            if mean_tuketim > self.adaptive_thresholds['yuksek_tuketim_esik']:
                yorumlar.append("Anormal yÃ¼ksek tÃ¼ketim")
            
            if yorumlar:
                return " | ".join(yorumlar) + " - Acil inceleme Ã¶nerilir"
            else:
                return "YÃ¼ksek riskli tÃ¼ketim paterni - Ä°nceleme gerekli"
        
        elif risk_seviyesi == "Orta":
            if sifir_sayisi == 1:
                return "Tekil sÄ±fÄ±r tÃ¼ketim - Ä°zleme gerektirir"
            elif varyasyon_katsayisi > self.adaptive_thresholds['varyasyon_esik'] * 0.7:
                return "Orta seviyede tÃ¼ketim dalgalanmasÄ±"
            else:
                return "TÃ¼ketim davranÄ±ÅŸÄ±nda kÃ¼Ã§Ã¼k tutarsÄ±zlÄ±klar"
        
        else:
            yorumlar = [
                "Normal tÃ¼ketim paterni",
                "Stabil tÃ¼ketim alÄ±ÅŸkanlÄ±ÄŸÄ±", 
                "TutarlÄ± tÃ¼ketim davranÄ±ÅŸÄ±"
            ]
            return np.random.choice(yorumlar)
    
    def _create_default_analysis(self, yorum, risk_seviyesi, risk_puan):
        """VarsayÄ±lan analiz oluÅŸtur"""
        return {
            'yorum': yorum,
            'supheli_donemler': "Yok",
            'risk_seviyesi': risk_seviyesi,
            'risk_puan': risk_puan,
            'std_dev': 0,
            'mean_tuketim': 0
        }
    
    def get_learning_stats(self):
        """DetaylÄ± Ã¶ÄŸrenme istatistiklerini getir"""
        if not self.performance_history:
            return {
                'toplam_gozlem': 0,
                'basari_orani': 0,
                'adaptive_thresholds': self.adaptive_thresholds,
                'model_version': '1.1',
                'status': 'Sentetik veri ile baÅŸlatÄ±ldÄ±'
            }
        
        toplam_gozlem = len(self.performance_history)
        
        # GerÃ§ek feedback'leri filtrele (sentetik olmayanlar)
        real_feedbacks = [p for p in self.performance_history if not p.get('tesisat_no', '').startswith('SYNTHETIC_')]
        real_basari_orani = sum([p['basari'] for p in real_feedbacks]) / len(real_feedbacks) if real_feedbacks else 0
        
        # TÃ¼m feedback'ler
        total_basari_orani = sum([p['basari'] for p in self.performance_history]) / toplam_gozlem
        
        return {
            'toplam_gozlem': toplam_gozlem,
            'gercek_gozlem': len(real_feedbacks),
            'basari_orani': total_basari_orani,
            'gercek_basari_orani': real_basari_orani,
            'adaptive_thresholds': self.adaptive_thresholds,
            'model_version': '1.1',
            'status': 'Aktif Ã¶ÄŸrenme modunda',
            'pattern_memory_size': len(self.pattern_memory)
        }

# Global adaptive model instance
adaptive_model = AdaptiveSuTuketimModeli()
