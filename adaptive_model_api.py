import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
from collections import defaultdict, deque
import re

warnings.filterwarnings('ignore')

class AdaptiveLearningModel:
    def __init__(self):
        # Ã–ÄŸrenme verisi
        self.learning_data = {
            'pattern_counts': defaultdict(int),
            'risk_patterns': defaultdict(list),
            'feedback_history': deque(maxlen=1000),
            'success_rates': defaultdict(float),
            'adaptive_thresholds': {
                'zero_consumption': 0.3,
                'high_consumption': 50.0,
                'variance_threshold': 0.4,
                'pattern_confidence': 0.7
            },
            'total_observations': 0,
            'real_observations': 0,
            'successful_predictions': 0
        }
        
        # Sentetik veri ile baÅŸlangÄ±Ã§ eÄŸitimi
        self._initialize_with_synthetic_data()
    
    def _initialize_with_synthetic_data(self):
        """Sentetik veri ile modeli baÅŸlangÄ±Ã§ eÄŸitimi"""
        print("ğŸ§  Sentetik veri ile baÅŸlangÄ±Ã§ eÄŸitimi yapÄ±lÄ±yor...")
        
        # Sentetik pattern Ã¶rnekleri
        synthetic_patterns = [
            # SÄ±fÄ±r aralÄ±klÄ± pattern (YÃ¼ksek risk)
            {'zeros_ratio': 0.4, 'variance': 0.8, 'max_consumption': 100, 'risk': 'YÃ¼ksek'},
            {'zeros_ratio': 0.3, 'variance': 0.7, 'max_consumption': 80, 'risk': 'YÃ¼ksek'},
            
            # YÃ¼ksek tÃ¼ketim pattern (Orta risk)
            {'zeros_ratio': 0.0, 'variance': 0.3, 'max_consumption': 150, 'risk': 'Orta'},
            {'zeros_ratio': 0.1, 'variance': 0.4, 'max_consumption': 120, 'risk': 'Orta'},
            
            # Normal pattern (DÃ¼ÅŸÃ¼k risk)
            {'zeros_ratio': 0.0, 'variance': 0.2, 'max_consumption': 50, 'risk': 'DÃ¼ÅŸÃ¼k'},
            {'zeros_ratio': 0.05, 'variance': 0.15, 'max_consumption': 40, 'risk': 'DÃ¼ÅŸÃ¼k'},
        ]
        
        for pattern in synthetic_patterns:
            features = {
                'zero_ratio': pattern['zeros_ratio'],
                'variance': pattern['variance'], 
                'max_consumption': pattern['max_consumption'],
                'pattern_type': self._classify_pattern(pattern)
            }
            
            self.learning_data['pattern_counts'][pattern['risk']] += 1
            self.learning_data['risk_patterns'][pattern['risk']].append(features)
            self.learning_data['total_observations'] += 1
            self.learning_data['real_observations'] += 1
        
        # BaÅŸlangÄ±Ã§ baÅŸarÄ± oranÄ±
        self.learning_data['successful_predictions'] = int(self.learning_data['real_observations'] * 0.85)
        
        print(f"âœ… Sentetik eÄŸitim tamamlandÄ±: {self.learning_data['real_observations']} Ã¶rnek")
    
    def _classify_pattern(self, features):
        """Pattern sÄ±nÄ±flandÄ±rma"""
        if features['zeros_ratio'] > 0.25:
            return 'sifir_aralikli'
        elif features['max_consumption'] > 80:
            return 'yuksek_tuketim'
        else:
            return 'normal'
    
    def gelismis_davranis_analizi(self, tesisat_verisi):
        """GeliÅŸmiÅŸ davranÄ±ÅŸ analizi ve pattern tanÄ±ma"""
        
        if len(tesisat_verisi) < 3:
            return self._default_analysis()
        
        try:
            # Temel istatistikler
            tuketimler = tesisat_verisi['AKTIF_m3'].values
            
            # Pattern Ã¶zellikleri Ã§Ä±karÄ±mÄ±
            features = self._extract_pattern_features(tuketimler)
            
            # Risk deÄŸerlendirmesi
            risk_analysis = self._assess_risk_with_learning(features)
            
            # Ã–ÄŸrenme gÃ¼ncellemesi
            self._update_learning(features, risk_analysis['risk_seviyesi'])
            
            return {
                'yorum': risk_analysis['yorum'],
                'supheli_donemler': risk_analysis['supheli_donemler'],
                'risk_seviyesi': risk_analysis['risk_seviyesi'],
                'risk_puan': risk_analysis['risk_puan'],
                'pattern_data': features
            }
            
        except Exception as e:
            print(f"Analiz hatasÄ±: {e}")
            return self._default_analysis()
    
    def _extract_pattern_features(self, tuketimler):
        """Pattern Ã¶zelliklerini Ã§Ä±kar"""
        
        # Temel istatistikler
        mean_tuketim = np.mean(tuketimler)
        std_tuketim = np.std(tuketimler)
        max_tuketim = np.max(tuketimler)
        
        # SÄ±fÄ±r tÃ¼ketim analizi
        zero_ratio = np.sum(tuketimler == 0) / len(tuketimler)
        
        # Varyans analizi
        variance = std_tuketim / (mean_tuketim + 1e-8)  # SÄ±fÄ±ra bÃ¶lÃ¼nmeyi Ã¶nle
        
        # Pattern sÄ±nÄ±flandÄ±rma
        pattern_type = self._classify_consumption_pattern(zero_ratio, variance, max_tuketim)
        
        return {
            'zero_ratio': zero_ratio,
            'variance': variance,
            'mean_consumption': mean_tuketim,
            'max_consumption': max_tuketim,
            'pattern_type': pattern_type,
            'data_points': len(tuketimler)
        }
    
    def _classify_consumption_pattern(self, zero_ratio, variance, max_consumption):
        """TÃ¼ketim pattern'ini sÄ±nÄ±flandÄ±r"""
        
        # Adaptive threshold'larÄ± kullan
        zero_threshold = self.learning_data['adaptive_thresholds']['zero_consumption']
        high_threshold = self.learning_data['adaptive_thresholds']['high_consumption']
        var_threshold = self.learning_data['adaptive_thresholds']['variance_threshold']
        
        if zero_ratio > zero_threshold:
            return 'sifir_aralikli'
        elif max_consumption > high_threshold:
            return 'yuksek_tuketim'
        else:
            return 'normal'
    
    def _assess_risk_with_learning(self, features):
        """Ã–ÄŸrenilmiÅŸ bilgilerle risk deÄŸerlendirmesi"""
        
        # Pattern bazlÄ± risk skoru
        pattern_risk_weights = {
            'sifir_aralikli': 0.9,
            'yuksek_tuketim': 0.7, 
            'normal': 0.2
        }
        
        base_risk = pattern_risk_weights.get(features['pattern_type'], 0.5)
        
        # Ã–zellik bazlÄ± ayarlamalar
        if features['zero_ratio'] > 0.4:
            base_risk += 0.3
        elif features['zero_ratio'] > 0.2:
            base_risk += 0.15
            
        if features['variance'] > 0.8:
            base_risk += 0.2
        elif features['variance'] > 0.5:
            base_risk += 0.1
        
        # Risk seviyesi belirleme
        base_risk = max(0.1, min(0.95, base_risk))
        
        if base_risk > 0.7:
            risk_seviyesi = "YÃ¼ksek"
            risk_puan = 4
            yorum = f"ğŸš¨ {features['pattern_type']} patterni - Acil inceleme gerekli"
        elif base_risk > 0.4:
            risk_seviyesi = "Orta" 
            risk_puan = 2
            yorum = f"ğŸ“Š {features['pattern_type']} patterni - Ä°zleme gerektirir"
        else:
            risk_seviyesi = "DÃ¼ÅŸÃ¼k"
            risk_puan = 1
            yorum = f"âœ… {features['pattern_type']} patterni - DÃ¼ÅŸÃ¼k risk"
        
        # ÅÃ¼pheli dÃ¶nemler
        supheli_donemler = self._identify_suspicious_periods(features)
        
        return {
            'risk_seviyesi': risk_seviyesi,
            'risk_puan': risk_puan,
            'yorum': yorum,
            'supheli_donemler': supheli_donemler
        }
    
    def _identify_suspicious_periods(self, features):
        """ÅÃ¼pheli dÃ¶nemleri belirle"""
        
        suspicious_items = []
        
        if features['zero_ratio'] > 0.3:
            suspicious_items.append(f"%{features['zero_ratio']*100:.1f} sÄ±fÄ±r tÃ¼ketim")
            
        if features['variance'] > 0.7:
            suspicious_items.append("yÃ¼ksek deÄŸiÅŸkenlik")
            
        if features['max_consumption'] > 80:
            suspicious_items.append("aÅŸÄ±rÄ± tÃ¼ketim dÃ¶nemleri")
        
        if suspicious_items:
            return ", ".join(suspicious_items)
        else:
            return "Belirgin ÅŸÃ¼pheli dÃ¶nem yok"
    
    def _update_learning(self, features, actual_risk):
        """Ã–ÄŸrenme verisini gÃ¼ncelle"""
        
        # Pattern sayÄ±sÄ±nÄ± gÃ¼ncelle
        pattern_type = features['pattern_type']
        self.learning_data['pattern_counts'][actual_risk] += 1
        
        # GÃ¶zlem sayÄ±larÄ±nÄ± gÃ¼ncelle
        self.learning_data['total_observations'] += 1
        self.learning_data['real_observations'] += 1
        
        # BaÅŸarÄ± oranÄ±nÄ± gÃ¼ncelle (basit yaklaÅŸÄ±m)
        if actual_risk in ['YÃ¼ksek', 'Orta'] and features['pattern_type'] in ['sifir_aralikli', 'yuksek_tuketim']:
            self.learning_data['successful_predictions'] += 1
        elif actual_risk == 'DÃ¼ÅŸÃ¼k' and features['pattern_type'] == 'normal':
            self.learning_data['successful_predictions'] += 1
    
    def learn_from_feedback(self, tesisat_no, gercek_risk, tahmin_risk, metadata=None):
        """Geri bildirimden Ã¶ÄŸrenme"""
        
        feedback_data = {
            'tesisat_no': tesisat_no,
            'gercek_risk': gercek_risk,
            'tahmin_risk': tahmin_risk,
            'timestamp': datetime.now(),
            'metadata': metadata or {}
        }
        
        self.learning_data['feedback_history'].append(feedback_data)
        
        # BaÅŸarÄ± durumunu gÃ¼ncelle
        if gercek_risk == tahmin_risk:
            self.learning_data['successful_predictions'] += 1
        
        self.learning_data['total_observations'] += 1
    
    def get_learning_stats(self):
        """Ã–ÄŸrenme istatistiklerini getir"""
        
        total_obs = self.learning_data['total_observations']
        real_obs = self.learning_data['real_observations']
        success_obs = self.learning_data['successful_predictions']
        
        basari_orani = success_obs / total_obs if total_obs > 0 else 0.7
        
        # Pattern daÄŸÄ±lÄ±mÄ±
        pattern_dagilimi = dict(self.learning_data['pattern_counts'])
        
        return {
            'toplam_gozlem': total_obs,
            'gercek_gozlem': real_obs,
            'basari_orani': basari_orani,
            'ogrenme_hizi': real_obs / max(1, total_obs - real_obs),
            'pattern_dagilimi': pattern_dagilimi,
            'adaptive_thresholds': self.learning_data['adaptive_thresholds']
        }
    
    def _default_analysis(self):
        """VarsayÄ±lan analiz sonucu"""
        return {
            'yorum': 'Yetersiz veri nedeniyle temel analiz yapÄ±ldÄ±',
            'supheli_donemler': 'Yetersiz veri',
            'risk_seviyesi': 'Orta',
            'risk_puan': 2,
            'pattern_data': {}
        }

# Global model instance
adaptive_model = AdaptiveLearningModel()
