import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from datetime import datetime, timedelta
import warnings
import re
import os
import pickle
import requests
import json
import base64
import io
from typing import Dict, List, Optional
import hashlib

warnings.filterwarnings('ignore')

# ======================================================================
# GITHUB-BASED MODEL MANAGER
# ======================================================================
class GitHubModelManager:
    def __init__(self, repo_owner: str, repo_name: str, token: str = None):
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.token = token
        self.base_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents"
        
    def _get_headers(self):
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.token:
            headers["Authorization"] = f"token {self.token}"
        return headers
    
    def download_model(self, filepath: str = "models/river_model.pkl") -> Optional[object]:
        """GitHub'dan modeli indir"""
        try:
            url = f"{self.base_url}/{filepath}"
            response = requests.get(url, headers=self._get_headers())
            
            if response.status_code == 200:
                content = response.json()
                if 'content' in content:
                    # Base64 decode
                    model_data = base64.b64decode(content['content'])
                    model = pickle.loads(model_data)
                    st.sidebar.success("‚úÖ Model GitHub'dan y√ºklendi")
                    return model
            return None
        except Exception as e:
            st.sidebar.warning(f"‚ö†Ô∏è GitHub'dan model y√ºklenemedi: {e}")
            return None
    
    def upload_model(self, model: object, filepath: str = "models/river_model.pkl", 
                    commit_message: str = "Auto-update model") -> bool:
        """Modeli GitHub'a y√ºkle"""
        try:
            # Modeli serialize et
            model_bytes = pickle.dumps(model)
            model_b64 = base64.b64encode(model_bytes).decode()
            
            # √ñnce mevcut dosyayƒ± kontrol et (SHA gerekli)
            url = f"{self.base_url}/{filepath}"
            response = requests.get(url, headers=self._get_headers())
            
            data = {
                "message": commit_message,
                "content": model_b64,
                "branch": "main"
            }
            
            if response.status_code == 200:
                existing_file = response.json()
                data["sha"] = existing_file["sha"]
            
            # Dosyayƒ± y√ºkle
            response = requests.put(url, headers=self._get_headers(), json=data)
            
            if response.status_code in [200, 201]:
                st.sidebar.success("‚úÖ Model GitHub'a y√ºklendi")
                return True
            else:
                st.sidebar.error(f"‚ùå Model y√ºklenemedi: {response.status_code}")
                return False
                
        except Exception as e:
            st.sidebar.error(f"‚ùå Model y√ºkleme hatasƒ±: {e}")
            return False

# ======================================================================
# RIVER MODEL SERVICE (Lightweight - Bellek Optimize)
# ======================================================================
class RiverModelService:
    def __init__(self, github_manager: GitHubModelManager):
        self.github_manager = github_manager
        self.model = None
        self.load_model()
    
    def load_model(self):
        """Modeli GitHub'dan y√ºkle veya yeni olu≈ütur"""
        self.model = self.github_manager.download_model()
        
        if self.model is None:
            # Yeni model olu≈ütur
            try:
                from river import anomaly, preprocessing
                self.model = preprocessing.StandardScaler() | anomaly.HalfSpaceTrees(
                    n_estimators=25, 
                    height=8,
                    seed=42
                )
                st.sidebar.info("üÜï Yeni River modeli olu≈üturuldu")
            except ImportError:
                st.sidebar.warning("‚ùå River k√ºt√ºphanesi kurulu deƒüil")
                self.model = None
    
    def incremental_learn(self, data: List[Dict]) -> Dict:
        """Incremental learning yap"""
        if self.model is None:
            return {"status": "error", "message": "Model yok"}
        
        try:
            scores = []
            for record in data:
                # Feature extraction
                features = {
                    "tuketim": float(record.get('AKTIF_m3', 0)),
                    "gunluk_ort": float(record.get('GUNLUK_ORT_TUKETIM_m3', 0)),
                    "tutar": float(record.get('TOPLAM_TUTAR', 0))
                }
                
                # Score and learn
                score = self.model.score_one(features)
                self.model.learn_one(features)
                scores.append(score)
            
            # Modeli GitHub'a kaydet
            self.github_manager.upload_model(self.model)
            
            return {
                "status": "success",
                "processed_records": len(data),
                "avg_score": np.mean(scores) if scores else 0,
                "latest_scores": scores[-10:]  # Son 10 skor
            }
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    def predict(self, data: Dict) -> Dict:
        """Anomali skoru tahmini"""
        if self.model is None:
            return {"score": 0.0, "status": "error"}
        
        try:
            features = {
                "tuketim": float(data.get('AKTIF_m3', 0)),
                "gunluk_ort": float(data.get('GUNLUK_ORT_TUKETIM_m3', 0)),
                "tutar": float(data.get('TOPLAM_TUTAR', 0))
            }
            
            score = self.model.score_one(features)
            return {"score": score, "status": "success"}
        except:
            return {"score": 0.0, "status": "error"}

# ======================================================================
# VERƒ∞ ƒ∞≈ûLEME FONKSƒ∞YONLARI
# ======================================================================
@st.cache_data
def load_and_analyze_data(uploaded_file, zone_file):
    """ƒ∞ki dosyadan veriyi okur ve analiz eder"""
    try:
        df = pd.read_excel(uploaded_file)
        st.success(f"‚úÖ Ana veri ba≈üarƒ±yla y√ºklendi: {len(df)} kayƒ±t")
    except Exception as e:
        st.error(f"‚ùå Ana dosya okuma hatasƒ±: {e}")
        return None, None, None

    # Tarih formatƒ±nƒ± d√ºzelt
    df['ILK_OKUMA_TARIHI'] = pd.to_datetime(df['ILK_OKUMA_TARIHI'], format='%Y%m%d', errors='coerce')
    df['OKUMA_TARIHI'] = pd.to_datetime(df['OKUMA_TARIHI'], format='%Y%m%d', errors='coerce')
    
    # Tesisat numarasƒ± olan kayƒ±tlarƒ± filtrele
    df = df[df['TESISAT_NO'].notnull()]
    
    # Zone veri dosyasƒ±nƒ± oku
    kullanici_zone_verileri = {}
    if zone_file is not None:
        try:
            zone_excel_df = pd.read_excel(zone_file)
            st.success(f"‚úÖ Zone veri dosyasƒ± ba≈üarƒ±yla y√ºklendi: {len(zone_excel_df)} kayƒ±t")
            
            for idx, row in zone_excel_df.iterrows():
                if 'KARNE NO VE ADI' in row:
                    karne_adi = str(row['KARNE NO VE ADI']).strip()
                    karne_no_match = re.search(r'(\d{4})', karne_adi)
                    if karne_no_match:
                        karne_no = karne_no_match.group(1)
                        zone_bilgisi = {
                            'ad': karne_adi,
                            'verilen_su': row.get('VERƒ∞LEN SU Mƒ∞KTARI M3', 0),
                            'tahakkuk_m3': row.get('TAHAKKUK M3', 0),
                            'kayip_oran': row.get('BR√úT KAYIP KA√áAK ORANI\n%', 0)
                        }
                        kullanici_zone_verileri[karne_no] = zone_bilgisi
        except Exception as e:
            st.error(f"‚ùå Zone veri dosyasƒ± y√ºklenirken hata: {e}")

    # Davranƒ±≈ü analizi
    def perform_behavior_analysis(df):
        son_okumalar = df.sort_values('OKUMA_TARIHI').groupby('TESISAT_NO').last().reset_index()
        son_okumalar['OKUMA_PERIYODU_GUN'] = (son_okumalar['OKUMA_TARIHI'] - son_okumalar['ILK_OKUMA_TARIHI']).dt.days
        son_okumalar['OKUMA_PERIYODU_GUN'] = son_okumalar['OKUMA_PERIYODU_GUN'].clip(lower=1, upper=365)
        son_okumalar['GUNLUK_ORT_TUKETIM_m3'] = son_okumalar['AKTIF_m3'] / son_okumalar['OKUMA_PERIYODU_GUN']
        son_okumalar['GUNLUK_ORT_TUKETIM_m3'] = son_okumalar['GUNLUK_ORT_TUKETIM_m3'].clip(lower=0.001, upper=100)
        return son_okumalar

    son_okumalar = perform_behavior_analysis(df)
    
    # Kƒ±saltƒ±lmƒ±≈ü davranƒ±≈ü analizi fonksiyonu
    def tesisat_davranis_analizi(tesisat_no, son_okuma_row, df):
        tesisat_verisi = df[df['TESISAT_NO'] == tesisat_no].sort_values('OKUMA_TARIHI')
        
        if len(tesisat_verisi) < 3:
            return "Yetersiz veri", "Yetersiz kayƒ±t", "Orta"

        tuketimler = tesisat_verisi['AKTIF_m3'].values
        
        # Basitle≈ütirilmi≈ü risk analizi
        sifir_sayisi = sum(tuketimler == 0)
        std_dev = np.std(tuketimler) if len(tuketimler) > 1 else 0
        mean_tuketim = np.mean(tuketimler) if len(tuketimler) > 0 else 0
        varyasyon_katsayisi = std_dev / mean_tuketim if mean_tuketim > 0 else 0
        
        risk_seviyesi = "D√º≈ü√ºk"
        if sifir_sayisi >= 3 or varyasyon_katsayisi > 1.5 or tuketimler[-1] == 0:
            risk_seviyesi = "Y√ºksek"
        elif sifir_sayisi >= 1 or varyasyon_katsayisi > 0.8:
            risk_seviyesi = "Orta"

        yorumlar = ["Normal t√ºketim paterni"] if risk_seviyesi == "D√º≈ü√ºk" else ["T√ºketimde dalgalanma g√∂zlemleniyor"]
        
        return np.random.choice(yorumlar), "Yok", risk_seviyesi

    # T√ºm tesisatlar i√ßin davranƒ±≈ü analizi
    davranis_sonuclari = []
    for idx, row in son_okumalar.iterrows():
        yorum, supheli_donemler, risk = tesisat_davranis_analizi(row['TESISAT_NO'], row, df)
        davranis_sonuclari.append({
            'TESISAT_NO': row['TESISAT_NO'],
            'DAVRANIS_YORUMU': yorum,
            'SUPHELI_DONEMLER': supheli_donemler,
            'RISK_SEVIYESI': risk
        })

    davranis_df = pd.DataFrame(davranis_sonuclari)
    son_okumalar = son_okumalar.merge(davranis_df, on='TESISAT_NO', how='left')

    # Zone analizi
    zone_analizi = None
    if 'KARNE_NO' in df.columns:
        ekim_2024_df = df[(df['OKUMA_TARIHI'].dt.month == 10) & (df['OKUMA_TARIHI'].dt.year == 2024)]
        if len(ekim_2024_df) == 0:
            ekim_2024_df = df.copy()
        
        zone_analizi = ekim_2024_df.groupby('KARNE_NO').agg({
            'TESISAT_NO': 'count',
            'AKTIF_m3': 'sum',
            'TOPLAM_TUTAR': 'sum'
        }).reset_index()
        zone_analizi.columns = ['KARNE_NO', 'TESISAT_SAYISI', 'TOPLAM_TUKETIM', 'TOPLAM_GELIR']

        if kullanici_zone_verileri:
            zone_analizi['KARNE_NO'] = zone_analizi['KARNE_NO'].astype(str)
            kullanici_df = pd.DataFrame.from_dict(kullanici_zone_verileri, orient='index').reset_index()
            kullanici_df = kullanici_df.rename(columns={'index': 'KARNE_NO'})
            zone_analizi = zone_analizi.merge(kullanici_df, on='KARNE_NO', how='left')

    return df, son_okumalar, zone_analizi




# ======================================================================
# STREAMLIT ARAY√úZ - PROFESYONEL Mƒ∞MARƒ∞
# ======================================================================

# GitHub configuration - BUNLARI STREAMLIT CLOUD SECRETS'A EKLEYƒ∞N
GITHUB_OWNER = "your_username"  # GitHub kullanƒ±cƒ± adƒ±nƒ±z
GITHUB_REPO = "your_repo_name"  # Repo adƒ±
GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN", None)  # Streamlit Cloud secrets

# Initialize services
github_manager = GitHubModelManager(GITHUB_OWNER, GITHUB_REPO, GITHUB_TOKEN)
model_service = RiverModelService(github_manager)

st.set_page_config(
    page_title="Su T√ºketim AI Analiz - GitHub + Streamlit",
    page_icon="üíß",
    layout="wide"
)

st.title("üíß Su T√ºketim AI Analiz Sistemi")
st.markdown("üöÄ **Profesyonel Mimari: GitHub + Streamlit + Incremental Learning**")

# Sidebar - Model Y√∂netimi
st.sidebar.header("üß† AI Model Y√∂netimi")

# Model durumu
if model_service.model is not None:
    st.sidebar.success("‚úÖ River Modeli Aktif")
else:
    st.sidebar.warning("‚ö†Ô∏è River Modeli Devre Dƒ±≈üƒ±")

# Model i≈ülemleri
col1, col2 = st.sidebar.columns(2)
with col1:
    if st.button("üîÑ Modeli G√ºncelle"):
        model_service.load_model()
        st.rerun()

with col2:
    if st.button("üóëÔ∏è Modeli Sƒ±fƒ±rla"):
        # GitHub'dan modeli sil (opsiyonel - manual yapƒ±labilir)
        st.info("Modeli sƒ±fƒ±rlamak i√ßin GitHub'dan models/river_model.pkl dosyasƒ±nƒ± silin")
        st.rerun()

# Dosya y√ºkleme
st.sidebar.header("üìÅ Veri Y√ºkleme")
uploaded_file = st.sidebar.file_uploader(
    "Ana Excel dosyasƒ±nƒ± se√ßin",
    type=["xlsx"],
    help="Su t√ºketim verilerini i√ßeren Excel dosyasƒ±nƒ± y√ºkleyin"
)

zone_file = st.sidebar.file_uploader(
    "Zone Excel dosyasƒ±nƒ± se√ßin", 
    type=["xlsx"],
    help="Zone bilgilerini i√ßeren Excel dosyasƒ±nƒ± y√ºkleyin"
)

# Incremental Learning Kontrol√º
st.sidebar.header("üîÅ Incremental Learning")
auto_learn = st.sidebar.checkbox("Otomatik √ñƒürenme", value=True, 
                                help="Yeni veri y√ºklendiƒüinde otomatik √∂ƒüren")

batch_size = st.sidebar.slider("Batch Boyutu", 10, 1000, 100, 
                              help="Aynƒ± anda i≈ülenecek kayƒ±t sayƒ±sƒ±")

# Demo verisi
if st.sidebar.button("üéÆ Demo Modu"):
    # Demo verisi olu≈ütur
    np.random.seed(42)
    demo_data = []
    for i in range(500):  # Daha k√º√ß√ºk demo
        tesisat_no = f"TS{1000 + i}"
        aktif_m3 = np.random.gamma(2, 10)
        
        demo_data.append({
            'TESISAT_NO': tesisat_no,
            'AKTIF_m3': max(aktif_m3, 0.1),
            'TOPLAM_TUTAR': aktif_m3 * 15,
            'ILK_OKUMA_TARIHI': pd.Timestamp('2023-01-01'),
            'OKUMA_TARIHI': pd.Timestamp('2024-10-31'),
            'KARNE_NO': f"ZONE{np.random.randint(1, 6)}"
        })
    
    df = pd.DataFrame(demo_data)
    son_okumalar = df.copy()
    son_okumalar['OKUMA_PERIYODU_GUN'] = 300
    son_okumalar['GUNLUK_ORT_TUKETIM_m3'] = son_okumalar['AKTIF_m3'] / son_okumalar['OKUMA_PERIYODU_GUN']
    
    risk_dagilimi = np.random.choice(['D√º≈ü√ºk', 'Orta', 'Y√ºksek'], size=len(son_okumalar), p=[0.7, 0.2, 0.1])
    son_okumalar['RISK_SEVIYESI'] = risk_dagilimi
    son_okumalar['DAVRANIS_YORUMU'] = "Demo verisi"
    son_okumalar['SUPHELI_DONEMLER'] = "Yok"
    
    zone_analizi = df.groupby('KARNE_NO').agg({
        'TESISAT_NO': 'count',
        'AKTIF_m3': 'sum', 
        'TOPLAM_TUTAR': 'sum'
    }).reset_index()
    
    st.success("‚úÖ Demo verisi olu≈üturuldu!")

elif uploaded_file is not None:
    # Ger√ßek veri y√ºkleme
    df, son_okumalar, zone_analizi = load_and_analyze_data(uploaded_file, zone_file)
    
    # Incremental Learning
    if auto_learn and model_service.model is not None and df is not None:
        with st.sidebar:
            with st.spinner("ü§ñ AI √∂ƒüreniyor..."):
                # Batch processing - belleƒüi koru
                records = df.head(batch_size).to_dict('records')
                result = model_service.incremental_learn(records)
                
                if result["status"] == "success":
                    st.success(f"‚úÖ {result['processed_records']} kayƒ±t i≈ülendi")
                    
                    # River skorlarƒ±nƒ± ekle
                    if 'RIVER_SCORE_MEAN' not in son_okumalar.columns:
                        # Tesisat bazƒ±nda River skorlarƒ± hesapla
                        river_scores = []
                        for _, row in son_okumalar.iterrows():
                            prediction = model_service.predict(row.to_dict())
                            river_scores.append(prediction['score'])
                        
                        son_okumalar['RIVER_SCORE'] = river_scores
                else:
                    st.error(f"‚ùå √ñƒürenme hatasƒ±: {result['message']}")
else:
    st.warning("‚ö†Ô∏è L√ºtfen Excel dosyasƒ±nƒ± y√ºkleyin veya Demo modunu kullanƒ±n")
    st.stop()

# ======================================================================
# DASHBOARD G√ñRSELLE≈ûTƒ∞RME
# ======================================================================

# Genel Metrikler
if son_okumalar is not None:
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Toplam Tesisat", f"{len(son_okumalar):,}")
    
    with col2:
        st.metric("üíß Toplam T√ºketim", f"{son_okumalar['AKTIF_m3'].sum():,.0f} m¬≥")
    
    with col3:
        st.metric("üí∞ Toplam Gelir", f"{son_okumalar['TOPLAM_TUTAR'].sum():,.0f} TL")
    
    with col4:
        yuksek_riskli = len(son_okumalar[son_okumalar['RISK_SEVIYESI'] == 'Y√ºksek'])
        st.metric("üö® Y√ºksek Riskli", f"{yuksek_riskli}")

# Tab Men√º
tab1, tab2, tab3, tab4 = st.tabs([
    "üìà Genel G√∂r√ºn√ºm", 
    "üó∫Ô∏è Zone Analizi", 
    "üîç Detaylƒ± Analiz",
    "ü§ñ AI Insights"
])

with tab1:
    if son_okumalar is not None:
        col1, col2 = st.columns(2)
        
        with col1:
            fig1 = px.histogram(son_okumalar, x='GUNLUK_ORT_TUKETIM_m3', 
                              title='G√ºnl√ºk T√ºketim Daƒüƒ±lƒ±mƒ±',
                              color_discrete_sequence=['#3498DB'])
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.scatter(son_okumalar, x='AKTIF_m3', y='TOPLAM_TUTAR',
                            color='RISK_SEVIYESI',
                            title='T√ºketim-Tutar ƒ∞li≈ükisi',
                            color_discrete_map={'D√º≈ü√ºk': 'green', 'Orta': 'orange', 'Y√ºksek': 'red'})
            st.plotly_chart(fig2, use_container_width=True)

with tab2:
    if zone_analizi is not None:
        col1, col2 = st.columns(2)
        
        with col1:
            fig3 = px.pie(zone_analizi, values='TOPLAM_TUKETIM', names='KARNE_NO',
                         title='Zone Bazlƒ± T√ºketim Daƒüƒ±lƒ±mƒ±')
            st.plotly_chart(fig3, use_container_width=True)
        
        with col2:
            fig4 = px.bar(zone_analizi, x='KARNE_NO', y='TESISAT_SAYISI',
                         title='Zone Bazlƒ± Tesisat Sayƒ±sƒ±')
            st.plotly_chart(fig4, use_container_width=True)

with tab3:
    if son_okumalar is not None:
        # Filtreleme ve detaylƒ± analiz
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("Filtreleme")
            risk_seviyeleri = st.multiselect(
                "Risk Seviyeleri",
                options=['D√º≈ü√ºk', 'Orta', 'Y√ºksek'],
                default=['Y√ºksek', 'Orta']
            )
        
        with col2:
            filtreli_veri = son_okumalar[son_okumalar['RISK_SEVIYESI'].isin(risk_seviyeleri)]
            st.dataframe(
                filtreli_veri[['TESISAT_NO', 'AKTIF_m3', 'TOPLAM_TUTAR', 'RISK_SEVIYESI', 'DAVRANIS_YORUMU']].head(20),
                use_container_width=True
            )

with tab4:
    st.header("ü§ñ AI - River Model Insights")
    
    if son_okumalar is not None and 'RIVER_SCORE' in son_okumalar.columns:
        col1, col2 = st.columns(2)
        
        with col1:
            fig5 = px.histogram(son_okumalar, x='RIVER_SCORE', 
                              title='River Anomali Skor Daƒüƒ±lƒ±mƒ±',
                              nbins=30)
            st.plotly_chart(fig5, use_container_width=True)
        
        with col2:
            # En y√ºksek anomali skorlu tesisatlar
            high_anomaly = son_okumalar.nlargest(10, 'RIVER_SCORE')[['TESISAT_NO', 'RIVER_SCORE', 'AKTIF_m3', 'RISK_SEVIYESI']]
            st.dataframe(high_anomaly, use_container_width=True)
        
        # AI + Heuristic kombinasyonu
        st.subheader("üî• Kombine Risk Analizi")
        son_okumalar['KOMBINE_RISK'] = np.where(
            (son_okumalar['RISK_SEVIYESI'] == 'Y√ºksek') | (son_okumalar['RIVER_SCORE'] > 0.7),
            'Y√ºksek', 
            np.where(
                (son_okumalar['RISK_SEVIYESI'] == 'Orta') | (son_okumalar['RIVER_SCORE'] > 0.4),
                'Orta', 
                'D√º≈ü√ºk'
            )
        )
        
        fig6 = px.scatter(son_okumalar, x='AKTIF_m3', y='RIVER_SCORE',
                         color='KOMBINE_RISK', size='TOPLAM_TUTAR',
                         hover_data=['TESISAT_NO', 'DAVRANIS_YORUMU'],
                         title='AI + Heuristic Kombine Risk Analizi',
                         color_discrete_map={'Y√ºksek': 'red', 'Orta': 'orange', 'D√º≈ü√ºk': 'green'})
        st.plotly_chart(fig6, use_container_width=True)
        
    else:
        st.info("ü§ñ AI analiz i√ßin veri y√ºkleyin ve incremental learning'i aktif edin")

# Footer
st.markdown("---")
st.markdown("""
**üîß Sistem Mimarisi:** 
- üêç Python + Streamlit 
- üß† River (Incremental ML) 
- üìÅ GitHub Model Storage 
- ‚òÅÔ∏è Streamlit Cloud Deploy
""")
